{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "902dbaa9-c023-4cd5-957d-f5ef3f459edc",
   "metadata": {},
   "source": [
    "## This notebook serves to build a dataset similar to the one from the lab\n",
    "\n",
    " Written by Ana Hoban, last edited in 08/2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74f3d3cc-40b3-4b65-903d-9a968756ff32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import warnings\n",
    "import csv\n",
    "import openpyxl\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffdf79fd-0ffc-4eab-a601-00f2f79f3f80",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Loading the raw data\n",
    "\n",
    "##### Be careful to change:\n",
    "    1. language\n",
    "    2. groupe\n",
    "##### in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa42f6f9-f2de-435f-8ab6-d92ead8cf42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#only thing to touch in this notebook:\n",
    "\n",
    "#select language fr or ang\n",
    "lang = 'fr'\n",
    "\n",
    "#select group silent or aps\n",
    "gr = 'aps'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db94707d-8a28-4dcc-a21c-f6d1796146e0",
   "metadata": {},
   "source": [
    "#### _make changes in the following cell only if you want the directories or input/output filenames to be different_\n",
    "_*might have to change the delimiter as well_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22be7c41-00ac-45ae-a40c-7b04ab236c7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "#loading in all lists\n",
    "all_data = []\n",
    "\n",
    "if gr == 'silent':\n",
    "    MAX = 5\n",
    "elif gr == 'aps':\n",
    "    MAX = 9\n",
    "    \n",
    "print(MAX)\n",
    "\n",
    "for i in range(1,MAX): \n",
    "    # 1. online silent english data\n",
    "    if (gr == 'silent') & (lang == 'eng'):\n",
    "        data_file = open((\"C:/Users/anaho/Desktop/silent online task data/taskdata_list{}.csv\".format(i)), \"r\",encoding = 'utf-8')\n",
    "        log = pd.read_csv('C:/Users/anaho/Desktop/research/language/aps/analysis/Data/Logs/LOG_English_online_silent.csv')\n",
    "        output_alex = 'C:/Users/anaho/Desktop/research/Language/APS/analysis/Data/Processed data/EnglishOnline/english_online_silentData.csv'\n",
    "        output_formatted = 'C:/Users/anaho/Desktop/research/Language/APS/analysis/Data/Processed data/EnglishOnline/english_online_silentData_formatted.csv'\n",
    "\n",
    "    # 2. online aps english data\n",
    "    if (gr == 'aps') & (lang == 'eng'):\n",
    "        data_file = open((\"C:/Users/anaho/Desktop/Data_online_eng_aps/list{}.csv\".format(i)), \"r\",encoding = 'utf-8')\n",
    "        log = pd.read_csv('C:/Users/anaho/Desktop/research/language/aps/analysis/Data/Logs/LOG_English_online_aps.csv')\n",
    "        output_alex = 'C:/Users/anaho/Desktop/research/Language/APS/analysis/Data/Processed data/EnglishOnline/english_online_apsData.csv'\n",
    "        output_formatted = 'C:/Users/anaho/Desktop/research/Language/APS/analysis/Data/Processed data/EnglishOnline/english_online_apsData_formatted.csv'\n",
    "    \n",
    "    # 3. online silent french data:\n",
    "    if (gr == 'silent') & (lang == 'fr'):\n",
    "        data_file = open((\"C:/Users/anaho/Desktop/Amandine_silent_reading_csv/list{}.csv\".format(i)), \"r\",encoding = 'latin1')\n",
    "        log = pd.read_csv('C:/Users/anaho/Desktop/research/language/aps/analysis/Data/Logs/LOG_French_online_silent.csv')\n",
    "        output_alex = 'C:/Users/anaho/Desktop/research/Language/APS/analysis/Data/Processed data/FrenchOnline/french_online_silentData.csv'\n",
    "        output_formatted = 'C:/Users/anaho/Desktop/research/Language/APS/analysis/Data/Processed data/FrenchOnline/french_online_silentData_formatted.csv'\n",
    "        \n",
    "    # 4. online aps french data:\n",
    "    if (gr == 'aps') & (lang == 'fr'):\n",
    "        data_file = open((\"C:/Users/anaho/Desktop/Data_Amandine_APS/Data_Amandine_APS/list{}.csv\".format(i)), \"r\",encoding = 'latin1')\n",
    "        log = pd.read_csv('C:/Users/anaho/Desktop/research/language/aps/analysis/Data/Logs/LOG_French_online_aps.csv')\n",
    "        output_alex = 'C:/Users/anaho/Desktop/research/Language/APS/analysis/Data/Processed data/FrenchOnline/french_online_apsData.csv'\n",
    "        output_formatted = 'C:/Users/anaho/Desktop/research/Language/APS/analysis/Data/Processed data/FrenchOnline/french_online_apsData_formatted.csv'\n",
    "\n",
    "    data = list(csv.reader(data_file, delimiter=\",\")) #skipping header\n",
    "    data_file.close()\n",
    "    all_data += data\n",
    "\n",
    "all_keys = all_data[0] #read in column names \n",
    "df = pd.DataFrame(all_data, columns = all_keys)\n",
    "\n",
    "#but we don't need all keys, let's keep only the following\n",
    "keys = [ 'Participant Public ID',\n",
    "         'Participant Status',\n",
    "         'Spreadsheet',\n",
    "         'Spreadsheet Row',\n",
    "         'Trial Number',\n",
    "         'Screen Number',\n",
    "         'Screen Name',\n",
    "         'Reaction Time',\n",
    "         'Response',\n",
    "         'Correct',\n",
    "         'Paraphrase',\n",
    "         'Phrase',\n",
    "         'Item',\n",
    "         'Structure',\n",
    "         'Plausibility']\n",
    "\n",
    "#photo key is only for APS\n",
    "if MAX == 9:\n",
    "    keys = keys + ['Photo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0690b712-017a-43f5-84ec-f7a34dc10905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we have  77 participants\n",
      "we have  144.004329004329 target trials per participant on avg\n"
     ]
    }
   ],
   "source": [
    "#define columns\n",
    "df = df[df['Participant Public ID'].isin(log['id'].unique())] \n",
    "\n",
    "#drop the columns that do not have data\n",
    "df = df[(df.Structure != '')]\n",
    "#df = df[(df.Structure != 'filler')]\n",
    "df = df[(df['Participant Status'] == 'complete')]\n",
    "\n",
    "#keep only needed keys\n",
    "df = df[keys]\n",
    "\n",
    "#making sure we have the right number of participants\n",
    "print('we have ' , len(df['Participant Public ID'].unique()),'participants')\n",
    "\n",
    "#for control\n",
    "#print('we have ' , len(silent_df)/( len(silent_df['Participant Public ID'].unique())*2), 'target trials per participant')\n",
    "#for aps\n",
    "print('we have ' , len(df)/( len(df['Participant Public ID'].unique())*3), 'target trials per participant on avg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1e170f8-f8bc-4a77-bc51-bc48972dc509",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#putting the accuracy information on the same line as the RT\n",
    "\n",
    "for ID in df['Participant Public ID'].unique():\n",
    "    for item in df.loc[df['Participant Public ID'] == ID, 'Spreadsheet Row'].unique():\n",
    "        paraphrase_answer = df.loc[ (df['Participant Public ID'] == ID ) & ( df['Spreadsheet Row'] == item)  & ( df['Screen Name'] == 'Screen : Paraphrase'), 'Correct'].values\n",
    "        \n",
    "         # Debug: print the extracted values\n",
    "        #print(f'ID: {ID}, Row: {item}, Paraphrase Answer: {paraphrase_answer}')\n",
    "        \n",
    "        #set new column for answer:\n",
    "        if len(paraphrase_answer) > 0: #check there is a value\n",
    "            paraphrase_answer = paraphrase_answer[0]\n",
    "            df.loc[\n",
    "                (df['Participant Public ID'] == ID) &\n",
    "                (df['Spreadsheet Row'] == item) &\n",
    "                (df['Screen Name'] == 'Screen : Phrase'),\n",
    "                'answer'\n",
    "            ] = paraphrase_answer\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "192e04f7-b40d-4127-bc83-f963753ef17f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, '1', '0'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.answer.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "517e5411-ceec-42e8-b986-82bf96cbd503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of target items:  11088\n",
      "Nb of target items per participant check:  144.0\n"
     ]
    }
   ],
   "source": [
    "#now we must remove all the paraphrase lines\n",
    "df = df[df['Screen Name'] == 'Screen : Phrase']\n",
    "print('Total number of target items: ', len(df))\n",
    "print('Nb of target items per participant check: ', len(df)/len(df['Participant Public ID'].unique()))\n",
    "\n",
    "#and assign blocks to the items: first 12 are in block 1, ... \n",
    "\n",
    "for ID in df['Participant Public ID'].unique():\n",
    "    df[df['Participant Public ID'] == ID]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ff30d3b-f764-4150-b66f-f4b3dbbe395b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the 'block' column to 0\n",
    "df['block'] = 0\n",
    "\n",
    "# Iterate over unique Participant Public ID\n",
    "for ID in df['Participant Public ID'].unique():\n",
    "    # Filter the dataframe for the current ID and only targets\n",
    "    participant_df = df.loc[(df['Participant Public ID'] == ID) & (df['Structure'] != 'filler'),'Trial Number'].drop_duplicates() \n",
    "    \n",
    "    # Check if the participant_df has exactly 48 rows\n",
    "    if len(participant_df) == 48:\n",
    "        # Assign blocks to each quarter\n",
    "        df.loc[participant_df.index[:12], 'block'] = 1\n",
    "        df.loc[participant_df.index[12:24], 'block'] = 2\n",
    "        df.loc[participant_df.index[24:36], 'block'] = 3\n",
    "        df.loc[participant_df.index[36:], 'block'] = 4\n",
    "    else:\n",
    "        print(f'Participant {ID} does not have exactly 48 rows.')\n",
    "        print(len(participant_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fdc9a515-7577-47b2-a0ea-28f725fb8e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the 'condition' column\n",
    "df['condition'] = None\n",
    "\n",
    "# Set conditions based on the specified rules\n",
    "df.loc[(df['Structure'] == 'SRC') & (df['Plausibility'] == 'plausible'), 'condition'] = 1\n",
    "df.loc[(df['Structure'] == 'SRC') & (df['Plausibility'] == 'implausible'), 'condition'] = 2\n",
    "df.loc[(df['Structure'] == 'ORC') & (df['Plausibility'] == 'plausible'), 'condition'] = 3\n",
    "df.loc[(df['Structure'] == 'ORC') & (df['Plausibility'] == 'implausible'), 'condition'] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d5deffd5-dfda-409a-9ade-6d3948b99ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of correct target items:  9751\n",
      "Proportion:  0.8794191919191919\n"
     ]
    }
   ],
   "source": [
    "correct_df = df[df.answer == '1']\n",
    "\n",
    "print('Total number of correct target items: ', len(correct_df))\n",
    "print('Proportion: ', len(correct_df)/len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6621482e-fca1-4b54-ae5a-cb5367a56d45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if MAX == 9 : #for aps dataset only\n",
    "    #must set speaker column to non-native or native\n",
    "    correct_df.speaker = ''\n",
    "    correct_df.loc[correct_df.Photo == 'WF.jpg', 'speech_condition'] = 'non-native' \n",
    "    correct_df.loc[correct_df.Photo == 'AF.jpg', 'speech_condition'] = 'native' \n",
    "\n",
    "    df.speaker = ''\n",
    "    df.loc[df.Photo == 'WF.jpg', 'speech_condition'] = 'non-native' \n",
    "    df.loc[df.Photo == 'AF.jpg', 'speech_condition'] = 'native' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "70f914be-49e5-4c65-860f-67c6bf3f8d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#download this dataset for Alex\n",
    "correct_df.to_csv(output_alex, header= True, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ccb11aba-503a-44e7-8d54-85854c8a15aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#create dictionnary to make column name match those of eyetracking data to be able to use that code\n",
    "col_names_dict = {\"Reaction Time\": \"SENTENCE_RT\", \"Participant Public ID\": \"Session_Name_\", \"answer\": \"PARAPHRASE_ACCURACY\",\n",
    "             \"Plausibility\": \"plausibility_condition\", \"Structure\": \"syntactic_condition\"}\n",
    "\n",
    "df['group'] = 'aps' \n",
    "df['sentence_type'] = 'target' \n",
    "\n",
    "\n",
    "df = df.rename(columns= col_names_dict)\n",
    "df.SENTENCE_RT =  pd.to_numeric(df.SENTENCE_RT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "71e9e6f5-674b-4551-994f-f61b51bc1fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(output_formatted, header= True, index = False, encoding = 'latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce9849f-31d8-4b73-912d-9e3312417edf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
